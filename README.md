# ğŸ•µï¸â€â™‚ï¸ Unicraft Scraper

A powerful, extensible Python scraper that:

- Searches DuckDuckGo or uses seed URLs
- Scrapes company info: emails, phones, descriptions, social links
- Extracts tech stack, market focus, positioning, and competitors
- Handles dynamic (JavaScript) content using Selenium
- Crawls internal pages (like /about, /products)
- Supports command-line usage and automatic scheduling (via APScheduler)

---

## ğŸš€ Features

- ğŸ” DuckDuckGo search integration
- âš™ï¸ Advanced scraping with BeautifulSoup + Selenium
- ğŸ“Š Multi-level insights (tech, focus, market)
- ğŸ” Scheduled scraping every 6 hours
- ğŸ“¦ Outputs clean JSON file (`output.json`)

---

## ğŸ›  Installation

1. **Clone the repo**:

```bash
git clone https://github.com/YOUR_USERNAME/unicraft_scraper.git
cd unicraft_scraper
```

2. **Install dependencies**:

```bash
pip install -r requirements.txt
```

3. **Add `chromedriver.exe`**

- Download from: https://sites.google.com/chromium.org/driver/
- Match it to your installed Chrome version
- Place the `.exe` in the project root

---

## âš™ï¸ Usage

### Run once with a query:
```bash
python main.py --query "top SaaS companies India"
```

### Run with seed URLs:
```bash
python main.py --urls "https://zerodha.com, https://cred.club"
```

### Run every 6 hours (scheduled):
```bash
python main.py --schedule
```

---

## ğŸ“‚ Output Format (`output.json`)
```json
{
  "url": "https://example.com",
  "company_name": "Example Inc.",
  "emails": ["info@example.com"],
  "phones": ["+91 12345 67890"],
  "description": "Indiaâ€™s top SaaS platform...",
  "social_links": ["https://linkedin.com/company/example"],
  "tech_stack": ["React", "Node.js", "AWS"],
  "focus_areas": ["Payment automation", "Digital banking"],
  "market_positioning": "Trusted by 200+ businesses",
  "competitors": ["Zoho", "Freshworks"]
}
```

---

## ğŸ§ª Dev Tips

- ğŸ§¼ Don't commit `chromedriver.exe` or `output.json`
- Add new tech terms to `extract_tech_stack()` in `scraper.py`
- Add new patterns in `extract_focus_areas()` to improve results

---

## ğŸ“Œ License

MIT Â© 2025 Diwansh Sood
